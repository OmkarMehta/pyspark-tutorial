{"cells":[{"cell_type":"markdown","source":["# PySpark â€“ Create DataFrame with Examples\n## &copy;  [Omkar Mehta](omehta2@illinois.edu) ##\n### Industrial and Enterprise Systems Engineering, The Grainger College of Engineering,  UIUC ###\n\n<hr style=\"border:2px solid blue\"> </hr>\n\nYou can manually create a PySpark DataFrame using `toDF()` and `createDataFrame()` methods, both these function takes different signatures in order to create DataFrame from existing RDD, list, and DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"36bcfc31-c8e8-4f71-84c9-e554b0f39094"}}},{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession, Row\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType\nfrom pyspark.sql.functions import *\n\n# Dataframe from list\ncolumns = [\"language\",\"users_count\"]\ndata = [(\"Java\", \"20000\"), (\"Python\", \"100000\"), (\"Scala\", \"3000\")]\n\n# Create rdd first\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\nrdd = spark.sparkContext.parallelize(data)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"05519fa4-70e4-4a22-ba9a-3b48baac2b71"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Use toDF() from rdd\ndfFromRDD1 = rdd.toDF()\ndfFromRDD1.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"60bfce79-07a7-4425-b69e-a6ec3e57597c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- _1: string (nullable = true)\n |-- _2: string (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- _1: string (nullable = true)\n-- _2: string (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Add columns to it\ncolumns = [\"language\",\"users_count\"]\ndfFromRDD1 = rdd.toDF(columns)\ndfFromRDD1.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3656c9f9-6571-4a2c-8d2e-85e52c23b6af"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- language: string (nullable = true)\n |-- users_count: string (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- language: string (nullable = true)\n-- users_count: string (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Use CreateDataFrame on rdd object\ndfFromRDD2 = spark.createDataFrame(rdd).toDF(*columns)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04c8348a-1f59-4aca-8342-40afe26ad171"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Use CreateDataFrame on list object\ndfFromData2 = spark.createDataFrame(data).toDF(*columns)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d1edff34-9d6f-4b82-b89e-629dd9971e77"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Using createDataFrame() with the Row type\nrowData = map(lambda x: Row(*x), data) \ndfFromData3 = spark.createDataFrame(rowData,columns)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b926ee9-5e7c-45cb-b317-7a8e125658c3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Create DataFrame with schema\ndata2 = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n  ]\n\nschema = StructType([ \\\n    StructField(\"firstname\",StringType(),True), \\\n    StructField(\"middlename\",StringType(),True), \\\n    StructField(\"lastname\",StringType(),True), \\\n    StructField(\"id\", StringType(), True), \\\n    StructField(\"gender\", StringType(), True), \\\n    StructField(\"salary\", IntegerType(), True) \\\n  ])\n \ndf = spark.createDataFrame(data=data2,schema=schema)\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5ab0d9ff-a7a9-430c-824b-66bc9e01e26e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- id: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n+---------+----------+--------+-----+------+------+\n|firstname|middlename|lastname|id   |gender|salary|\n+---------+----------+--------+-----+------+------+\n|James    |          |Smith   |36636|M     |3000  |\n|Michael  |Rose      |        |40288|M     |4000  |\n|Robert   |          |Williams|42114|M     |4000  |\n|Maria    |Anne      |Jones   |39192|F     |4000  |\n|Jen      |Mary      |Brown   |     |F     |-1    |\n+---------+----------+--------+-----+------+------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- firstname: string (nullable = true)\n-- middlename: string (nullable = true)\n-- lastname: string (nullable = true)\n-- id: string (nullable = true)\n-- gender: string (nullable = true)\n-- salary: integer (nullable = true)\n\n+---------+----------+--------+-----+------+------+\nfirstname|middlename|lastname|id   |gender|salary|\n+---------+----------+--------+-----+------+------+\nJames    |          |Smith   |36636|M     |3000  |\nMichael  |Rose      |        |40288|M     |4000  |\nRobert   |          |Williams|42114|M     |4000  |\nMaria    |Anne      |Jones   |39192|F     |4000  |\nJen      |Mary      |Brown   |     |F     |-1    |\n+---------+----------+--------+-----+------+------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Create DataFrame from Data sources\ndf2 = spark.read.csv(\"/FileStore/tables/covid_analytics_clinical_data.csv\")\n#df2.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e4671842-e6ea-4db9-aa08-4dbad101abff"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Creating from text (TXT) file\ndf2 = spark.read.text(\"/FileStore/tables/data.txt\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1933fb5f-2579-43c2-8554-42489e38c082"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Creating from JSON file\ndf2 = spark.read.json(\"/FileStore/tables/example_1.json\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0ebe123-f80e-4adc-bb3b-bbd99a7bf3e3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Spark Check Column Present in DataFrame\n\nYou can get all columns of a DataFrame as an Array[String] by using columns attribute of Spark DataFrame and use this with Scala Array functions to check if a column/field present in DataFrame, In this article I will also cover how to check if a column present/exists in nested column and by case insensitive.\n\n### Check Column Exists by Case insensitive"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ada1567a-6ee9-4edd-b7c0-cfec4c3d6c91"}}},{"cell_type":"code","source":["%scala \ndf2 = spark.read.csv(\"/FileStore/tables/covid_analytics_clinical_data.csv\")\n\n\ndf2.columns.map(_.toUpperCase).contains(columnNameToCheck.toUpperCase)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"969a17e5-9516-46f1-a84e-021a24dfb1db"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"<div class=\"ansiout\">command-2343:2: error: not found: value df2\ndf2 = spark.read.csv(&quot;/FileStore/tables/covid_analytics_clinical_data.csv&quot;)\n^\ncommand-2343:5: error: not found: value df2\ndf2.columns.map(_.toUpperCase).contains(columnNameToCheck.toUpperCase)\n^\ncommand-2343:5: error: not found: value columnNameToCheck\ndf2.columns.map(_.toUpperCase).contains(columnNameToCheck.toUpperCase)\n                                        ^\ncommand-2343:46: error: not found: value df2\nval $ires3 = df2\n             ^\n</div>","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# PySpark Read and Write Parquet File"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c01fadfb-f2dd-425e-bd03-0cf0b59a5fbe"}}},{"cell_type":"code","source":["df.write.parquet(\"/tmp/out/people.parquet\") \nparDF1=spark.read.parquet(\"/temp/out/people.parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6bfa138b-15d5-4a50-82cf-88626374203b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["\ndata =[(\"James \",\"\",\"Smith\",\"36636\",\"M\",3000),\n              (\"Michael \",\"Rose\",\"\",\"40288\",\"M\",4000),\n              (\"Robert \",\"\",\"Williams\",\"42114\",\"M\",4000),\n              (\"Maria \",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n              (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)]\ncolumns=[\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\ndf=spark.createDataFrame(data,columns)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a6f13eb-b316-44c2-a9c9-acd2da064275"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Pyspark Write DataFrame to Parquet file format\ndf.write.parquet(\"/FileStore/tables/people.parquet\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bee9e259-84c0-46f3-a053-cbd1b98812a7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Pyspark Read Parquet file into DataFrame\nparDF=spark.read.parquet(\"/FileStore/tables/people.parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"481ca66e-78eb-4d38-98ce-01532bcdcb47"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# # Append or Overwrite an existing Parquet file\n# df.write.mode('append').parquet(\"/tmp/output/people.parquet\")\n# df.write.mode('overwrite').parquet(\"/tmp/output/people.parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ef95367-d26f-4ec9-bdee-0be6ac6a2690"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Executing SQL queries DataFrame\nparDF.createOrReplaceTempView(\"ParquetTable\")\nparkSQL = spark.sql(\"select * from ParquetTable where salary >= 4000 \")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77b99945-fb29-42a1-844b-27a1f6ef08a2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Creating a table on Parquet file\nspark.sql(\"CREATE TEMPORARY VIEW PERSON USING parquet OPTIONS (path \\\"/FileStore/tables/people.parquet\\\")\")\nspark.sql(\"SELECT * FROM PERSON\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b2e0d69-d1bc-4613-a47e-b21fc85d3f8d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------+----------+--------+-----+------+------+\n|firstname|middlename|lastname|  dob|gender|salary|\n+---------+----------+--------+-----+------+------+\n|  Robert |          |Williams|42114|     M|  4000|\n| Michael |      Rose|        |40288|     M|  4000|\n|   James |          |   Smith|36636|     M|  3000|\n|   Maria |      Anne|   Jones|39192|     F|  4000|\n|      Jen|      Mary|   Brown|     |     F|    -1|\n+---------+----------+--------+-----+------+------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+----------+--------+-----+------+------+\nfirstname|middlename|lastname|  dob|gender|salary|\n+---------+----------+--------+-----+------+------+\n  Robert |          |Williams|42114|     M|  4000|\n Michael |      Rose|        |40288|     M|  4000|\n   James |          |   Smith|36636|     M|  3000|\n   Maria |      Anne|   Jones|39192|     F|  4000|\n      Jen|      Mary|   Brown|     |     F|    -1|\n+---------+----------+--------+-----+------+------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Create Parquet partition file\n\ndf.write.partitionBy(\"gender\",\"salary\").mode(\"overwrite\").parquet(\"/FileStore/tables/people2.parquet\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee634076-ffa9-42c3-bd51-40ab2928c164"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Retrieving from a partitioned Parquet file\n\nparDF2=spark.read.parquet(\"/FileStore/tables/people2.parquet/gender=M\")\nparDF2.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b528e85d-b071-4833-afca-3dc6e8e164ed"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------+----------+--------+-----+------+\n|firstname|middlename|lastname|dob  |salary|\n+---------+----------+--------+-----+------+\n|Michael  |Rose      |        |40288|4000  |\n|James    |          |Smith   |36636|3000  |\n|Robert   |          |Williams|42114|4000  |\n+---------+----------+--------+-----+------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+----------+--------+-----+------+\nfirstname|middlename|lastname|dob  |salary|\n+---------+----------+--------+-----+------+\nMichael  |Rose      |        |40288|4000  |\nJames    |          |Smith   |36636|3000  |\nRobert   |          |Williams|42114|4000  |\n+---------+----------+--------+-----+------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Creating a table on Partitioned Parquet file\n\nspark.sql(\"CREATE TEMPORARY VIEW PERSON2 USING parquet OPTIONS (path \\\"/FileStore/tables/people2.parquet/gender=F\\\")\")\nspark.sql(\"SELECT * FROM PERSON2\" ).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4b44c569-fd13-4ab1-8117-24388833b4ca"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------+----------+--------+-----+------+\n|firstname|middlename|lastname|  dob|salary|\n+---------+----------+--------+-----+------+\n|      Jen|      Mary|   Brown|     |    -1|\n|   Maria |      Anne|   Jones|39192|  4000|\n+---------+----------+--------+-----+------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+----------+--------+-----+------+\nfirstname|middlename|lastname|  dob|salary|\n+---------+----------+--------+-----+------+\n      Jen|      Mary|   Brown|     |    -1|\n   Maria |      Anne|   Jones|39192|  4000|\n+---------+----------+--------+-----+------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"849490e1-6406-4f72-a101-eb0b0fabf549"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-dataframe-tutorial-omkar.ipynb","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2269}},"nbformat":4,"nbformat_minor":0}
